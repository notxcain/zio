"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[71317],{15680:(e,t,n)=>{n.d(t,{xA:()=>p,yg:()=>d});var a=n(96540);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},m="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=u(n),c=r,d=m["".concat(s,".").concat(c)]||m[c]||g[c]||i;return n?a.createElement(d,o(o({ref:t},p),{},{components:n})):a.createElement(d,o({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=c;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:r,o[1]=l;for(var u=2;u<i;u++)o[u]=n[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},88290:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>g,frontMatter:()=>i,metadata:()=>l,toc:()=>u});var a=n(58168),r=(n(96540),n(15680));const i={id:"consumer-tuning",title:"Tuning the consumer"},o=void 0,l={unversionedId:"zio-kafka/consumer-tuning",id:"zio-kafka/consumer-tuning",title:"Tuning the consumer",description:"Zio-kafka's consumer can be tuned with the ConsumerSettings class.",source:"@site/docs/zio-kafka/consumer-tuning.md",sourceDirName:"zio-kafka",slug:"/zio-kafka/consumer-tuning",permalink:"/zio-kafka/consumer-tuning",draft:!1,editUrl:"https://github.com/zio/zio/edit/series/2.x/docs/zio-kafka/consumer-tuning.md",tags:[],version:"current",frontMatter:{id:"consumer-tuning",title:"Tuning the consumer"},sidebar:"ecosystem-sidebar",previous:{title:"Partition Assignment And Offset Retrieval",permalink:"/zio-kafka/partition-assignment-and-offset-retrieval"},next:{title:"Sharing a Consumer between multiple streams",permalink:"/zio-kafka/sharing-consumer"}},s={},u=[{value:"Names",id:"names",level:2},{value:"Throughput and latency",id:"throughput-and-latency",level:2},{value:"Small and large records",id:"small-and-large-records",level:2},{value:"High number of partitions",id:"high-number-of-partitions",level:2},{value:"Long processing durations",id:"long-processing-durations",level:2}],p={toc:u},m="wrapper";function g(e){let{components:t,...n}=e;return(0,r.yg)(m,(0,a.A)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("p",null,"Zio-kafka's consumer can be tuned with the ",(0,r.yg)("inlineCode",{parentName:"p"},"ConsumerSettings")," class. "),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-scala"},"val settings = ConsumerSettings(bootstrapServers)\n  .withGroupId(groupId)\n  .withProperties(properties)\n  .... etc.\n")),(0,r.yg)("h2",{id:"names"},"Names"),(0,r.yg)("p",null,"Two very similarly named settings are relevant. Don't mix them up:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"pollTimeout")," \u2014 how long a poll may take"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"max.poll.interval.ms")," \u2014 the maximum time between polls")),(0,r.yg)("h2",{id:"throughput-and-latency"},"Throughput and latency"),(0,r.yg)("p",null,"The kafka client can be tuned for either high throughput or low latency, unfortunately not both.\nThe most important settings for tuning throughput and latency are:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"zio-kafka's ",(0,r.yg)("inlineCode",{parentName:"li"},"pollTimeout")," \u2014 This is the maximum time to block while polling the Kafka consumer. Zio-kafka's default\nis ",(0,r.yg)("inlineCode",{parentName:"li"},"50ms")," which is good for low latency applications. Set this higher, e.g. ",(0,r.yg)("inlineCode",{parentName:"li"},"500ms")," for better throughput."),(0,r.yg)("li",{parentName:"ul"},"kafka's ",(0,r.yg)("a",{parentName:"li",href:"https://kafka.apache.org/documentation/#consumerconfigs_max.poll.records"},"configuration ",(0,r.yg)("inlineCode",{parentName:"a"},"max.poll.records"))," \u2014 The maximum number of records a poll will return. Kafka defaults\nthis to ",(0,r.yg)("inlineCode",{parentName:"li"},"500"),". You can set this higher for more throughput, or lower for lower latency."),(0,r.yg)("li",{parentName:"ul"},"zio-kafka's fetch-strategy ",(0,r.yg)("inlineCode",{parentName:"li"},"partitionPreFetchBufferLimit")," \u2014 when the number of records in a partition queue is\nat or below this value, zio-kafka will start to pre-fetch and buffer more records from Kafka. The default value for\nthis parameter is ",(0,r.yg)("inlineCode",{parentName:"li"},"1024"),"; 2 * the default ",(0,r.yg)("inlineCode",{parentName:"li"},"max.poll.records")," of 500, rounded to the nearest power of 2.")),(0,r.yg)("p",null,"Zio-kafka provides 2 methods that set these settings for 2 common use cases: ",(0,r.yg)("inlineCode",{parentName:"p"},"ConsumerSettings.tuneForHighThroughput"),"\nand ",(0,r.yg)("inlineCode",{parentName:"p"},"ConsumerSettings.tuneForLowLatency"),".\nNote that their implementation may vary over time. You can use them as follows:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-scala"},"val highThroughputSettings = ConsumerSettings(bootstrapServers).tuneForHighThroughput\nval lowLatencySettings = ConsumerSettings(bootstrapServers).tuneForLowLatency\n")),(0,r.yg)("h2",{id:"small-and-large-records"},"Small and large records"),(0,r.yg)("p",null,"Kafka\u2019s performance is not very sensitive to record size. However, when records become very small (< 100 bytes) it\nmight be beneficial to increase ",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.records")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"partitionPreFetchBufferLimit"),". Similarly, when records are\nvery large (> 100Kb), ",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.records")," can be decreased. Also, pre-fetching can be limited by decreasing\n",(0,r.yg)("inlineCode",{parentName:"p"},"partitionPreFetchBufferLimit")," or even disabled by using ",(0,r.yg)("inlineCode",{parentName:"p"},"ConsumerSettngs.withoutPartitionPreFetching"),"."),(0,r.yg)("h2",{id:"high-number-of-partitions"},"High number of partitions"),(0,r.yg)("p",null,"When a lot of partitions need to be consumed, we need to take into account that heap is needed to store the records in\nthe partition queues. A very rough estimate for the maximum amount of heap needed is given by: ",(0,r.yg)("inlineCode",{parentName:"p"},"average record size")," ",(0,r.yg)("em",{parentName:"p"},(0,r.yg)("inlineCode",{parentName:"em"},"number of of partitions")," ")," max(",(0,r.yg)("inlineCode",{parentName:"p"},"partitionPreFetchBufferLimit"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.records"),")."),(0,r.yg)("p",null,"The total can be tuned by changing the ",(0,r.yg)("inlineCode",{parentName:"p"},"partitionPreFetchBufferLimit"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.records")," settings."),(0,r.yg)("p",null,"Another option is to write a custom ",(0,r.yg)("inlineCode",{parentName:"p"},"FetchStrategy"),". For example the ",(0,r.yg)("inlineCode",{parentName:"p"},"ManyPartitionsQueueSizeBasedFetchStrategy")," in\n",(0,r.yg)("a",{parentName:"p",href:"https://github.com/zio/zio-kafka/pull/970"},"draft PR 970")," (not yet tested at scale, use at your own risk). Note that the fetch strategy API is marked as\nexperimental and may change without notice in any future zio-kafka version."),(0,r.yg)("h2",{id:"long-processing-durations"},"Long processing durations"),(0,r.yg)("p",null,"To detect stalled consumers, Kafka revokes a partition when a consumer does not poll within the max poll interval (see\n",(0,r.yg)("a",{parentName:"p",href:"https://kafka.apache.org/documentation/#consumerconfigs_max.poll.interval.ms"},"configuration ",(0,r.yg)("inlineCode",{parentName:"a"},"max.poll.interval.ms")),"). The default max poll interval is 5 minutes. After a partition is revoked,\nit will be assigned to another consumer."),(0,r.yg)("p",null,"In zio-kafka (versions 2.5.1+) a stream needs to pull data within the max poll interval. If this doesn't happen, the\nstream is interrupted with a failure and the whole consumer shuts down."),(0,r.yg)("p",null,"To see if your application must be configured with a higher ",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.interval.ms")," value we need to consider the\nmaximum duration between polls. If processing is sequential, we can obtain this maximum by multiplying\n",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.records")," with the maximum duration to process a single record. To also accommodate things like long garbage\ncollections and buffering, configuration ",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.interval.ms")," should be substantially higher than the maximum\nprocessing time."),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.interval.ms")," can be set with:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-scala"},"  .withMaxPollInterval(15.minutes)\n")),(0,r.yg)("p",null,"On older zio-kafka versions ",(0,r.yg)("inlineCode",{parentName:"p"},"withMaxPollInterval")," is not available. Use the following instead:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-scala"},'  .withProperty("max.poll.interval.ms", 15.minutes.toMillis.toString)\n')),(0,r.yg)("p",null,"\u26a0\ufe0fIn zio-kafka versions 2.2 up to 2.5.0 it may also be necessary to increase the ",(0,r.yg)("inlineCode",{parentName:"p"},"runloopTimeout")," setting.\nWhen no stream is processing data for this amount of time (while new data is available), the consumer will halt with a\nfailure. In zio-kafka 2.5.0 ",(0,r.yg)("inlineCode",{parentName:"p"},"runloopTimeout")," defaults to 4 minutes, a little bit lower than ",(0,r.yg)("inlineCode",{parentName:"p"},"max.poll.interval.ms"),"."))}g.isMDXComponent=!0}}]);